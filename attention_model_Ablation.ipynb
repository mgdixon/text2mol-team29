{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgdixon/text2mol-team29/blob/main/attention_model_Ablation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions\n",
        "\n",
        "This file is for the Attention flavor of the ablations. Using the global variables below, pick one of the ablations to run and give the model a name. The actual ablations are below:\n",
        "\n",
        "1. Use BERT instead of SciBERT to gauge the impact.\n",
        "1. Remove the learned temperature parameter from the general loss function to gauge the impact.\n",
        "1. Remove negative sampling from the loss function for the cross-modal attention model to gauge the impact.\n",
        "1. Use one token for each atom (r = 0) instead of two to gauge the impact.\n",
        "1. Remove layer normalization from the encoders to gauge the impact."
      ],
      "metadata": {
        "id": "WxPGhbtrRffr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ABLATION_1 = False\n",
        "ABLATION_2 = True\n",
        "ABLATION_3 = False\n",
        "ABLATION_4 = False\n",
        "ABLATION_5 = False\n",
        "MODEL = \"ATTN\"\n"
      ],
      "metadata": {
        "id": "RN_UmFApRqk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVnGSv6cxVKj"
      },
      "outputs": [],
      "source": [
        "!pip install  torch-geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ablations Planned\n",
        "\n",
        "1. Use BERT instead of SciBERT to gauge the impact.\n",
        "2. Remove the learned temperature parameter from the general loss function to gauge the impact.\n",
        "3. Remove negative sampling from the loss function for the cross-modal attention model to gauge the impact.\n",
        "4. Use one token for each atom (r = 0) instead of two to gauge the impact.\n",
        "5. Remove layer normalization from the encoders to gauge the impact.\n",
        "\n"
      ],
      "metadata": {
        "id": "H-89-W7R3lRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Install Cloud Storage FUSE.\n",
        "!echo \"deb https://packages.cloud.google.com/apt gcsfuse-`lsb_release -c -s` main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "!apt -qq update && apt -qq install gcsfuse"
      ],
      "metadata": {
        "id": "mSuANpOuImR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount a Cloud Storage bucket or location, without the gs:// prefix.\n",
        "mount_path = \"team29-text2mol\"  # or a location like \"my-bucket/path/to/mount\"\n",
        "local_path = f\"/mnt/gs/{mount_path}\"\n",
        "\n",
        "!mkdir -p {local_path}\n",
        "!gcsfuse --implicit-dirs {mount_path} {local_path}"
      ],
      "metadata": {
        "id": "UULM4HFbIoyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XgTpm9ZxoN9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "import math\n",
        "\n",
        "import csv\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Transformer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
        "\n",
        "\n",
        "import tokenizers\n",
        "from tokenizers import Tokenizer\n",
        "from transformers import BertTokenizerFast, BertModel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaoYuRw0o0W8"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "import zipfile\n",
        "\n",
        "import torch\n",
        "from torch_geometric.data import download_url, Data\n",
        "from torch_geometric.data import Dataset as GeoDataset\n",
        "from torch_geometric.data import DataLoader as GeoDataLoader\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if ABLATION_1:\n",
        "  output_path = local_path + \"/\" + MODEL + \"_Ablation_1/\"\n",
        "elif ABLATION_2:\n",
        "  output_path = local_path + \"/\" + MODEL + \"_Ablation_2/\"\n",
        "elif ABLATION_3:\n",
        "  output_path = local_path + \"/\" + MODEL + \"_Ablation_3/\"\n",
        "elif ABLATION_4:\n",
        "  output_path = local_path + \"/\" + MODEL + \"_Ablation_4/\"\n",
        "elif ABLATION_5:\n",
        "  output_path = local_path + \"/\" + MODEL + \"_Ablation_5/\"\n",
        "else:\n",
        "  output_path = local_path + \"/\" + MODEL + \"_NoAblation/\"\n",
        "\n",
        "data_path = local_path + \"/data/\"\n",
        "emb_path = output_path + \"embeddings/\"\n",
        "\n",
        "if not os.path.exists(output_path):\n",
        "  os.mkdir(output_path)\n",
        "\n",
        "if not os.path.exists(emb_path):\n",
        "  os.mkdir(emb_path)\n"
      ],
      "metadata": {
        "id": "-mlpS4z3Rzgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gpao3ymyTBg"
      },
      "outputs": [],
      "source": [
        "#Need a special generator for random sampling:\n",
        "\n",
        "\n",
        "class GenerateData():\n",
        "  def __init__(self, path_train, path_val, path_test, path_molecules,\n",
        "               path_token_embs, ablation_1 = False):\n",
        "    self.path_train = path_train\n",
        "    self.path_val = path_val\n",
        "    self.path_test = path_test\n",
        "    self.path_molecules = path_molecules\n",
        "    self.path_token_embs = path_token_embs\n",
        "    self.ablation_1 = ablation_1\n",
        "\n",
        "    self.mol_trunc_length = 512\n",
        "    self.text_trunc_length = 256\n",
        "\n",
        "    self.prep_text_tokenizer()\n",
        "\n",
        "    self.load_substructures()\n",
        "\n",
        "    self.batch_size = 32\n",
        "\n",
        "    self.store_descriptions()\n",
        "\n",
        "  def load_substructures(self):\n",
        "    self.molecule_sentences = {}\n",
        "    self.molecule_tokens = {}\n",
        "\n",
        "    total_tokens = set()\n",
        "    self.max_mol_length = 0\n",
        "    with open(self.path_molecules) as f:\n",
        "      for line in f:\n",
        "        spl = line.split(\":\")\n",
        "        cid = spl[0]\n",
        "        tokens = spl[1].strip()\n",
        "        self.molecule_sentences[cid] = tokens\n",
        "        t = tokens.split()\n",
        "        total_tokens.update(t)\n",
        "        size = len(t)\n",
        "        if size > self.max_mol_length: self.max_mol_length = size\n",
        "\n",
        "\n",
        "    self.token_embs = np.load(self.path_token_embs, allow_pickle = True)[()]\n",
        "\n",
        "\n",
        "\n",
        "  def prep_text_tokenizer(self):\n",
        "    if self.ablation_1:\n",
        "      self.text_tokenizer = BertTokenizerFast.from_pretrained(\"google-bert/bert-base-uncased\")\n",
        "    else:\n",
        "      self.text_tokenizer = BertTokenizerFast.from_pretrained('allenai/scibert_scivocab_uncased')\n",
        "\n",
        "# Refactored version that's much shorter\n",
        "  def read_file(self, file_path):\n",
        "    cids = []\n",
        "    with open(file_path) as f:\n",
        "        reader = csv.DictReader(f, delimiter=\"\\t\", quoting=csv.QUOTE_NONE,\n",
        "                                fieldnames=['cid', 'mol2vec', 'desc'])\n",
        "        for line in reader:\n",
        "            self.descriptions[line['cid']] = line['desc']\n",
        "            self.mols[line['cid']] = line['mol2vec']\n",
        "            cids.append(line['cid'])\n",
        "    return cids\n",
        "\n",
        "  def store_descriptions(self):\n",
        "    self.descriptions = {}\n",
        "    self.mols = {}\n",
        "    self.training_cids = self.read_file(self.path_train)\n",
        "    self.validation_cids = self.read_file(self.path_val)\n",
        "    self.test_cids = self.read_file(self.path_test)\n",
        "\n",
        "  #transformers can't take array with full attention so have to pad a 0...\n",
        "  def padarray(self, A, size, value=0):\n",
        "      t = size - len(A)\n",
        "      return np.pad(A, pad_width=(0, t), mode='constant', constant_values = value)\n",
        "\n",
        "\n",
        "  def generate_examples_train(self):\n",
        "    \"\"\"Yields examples.\"\"\"\n",
        "\n",
        "    np.random.shuffle(self.training_cids)\n",
        "\n",
        "    for cid in self.training_cids:\n",
        "      label = np.random.randint(2)\n",
        "      rand_cid = np.random.choice(self.training_cids)\n",
        "      if label:\n",
        "        text_input = self.text_tokenizer(self.descriptions[cid], truncation=True, max_length=self.text_trunc_length - 1,\n",
        "                                        padding='max_length', return_tensors = 'np')\n",
        "      else:\n",
        "        text_input = self.text_tokenizer(self.descriptions[rand_cid], truncation=True, max_length=self.text_trunc_length - 1,\n",
        "                                        padding='max_length', return_tensors = 'np')\n",
        "\n",
        "      text_ids = self.padarray(text_input['input_ids'].squeeze(), self.text_trunc_length)\n",
        "      text_mask = self.padarray(text_input['attention_mask'].squeeze(), self.text_trunc_length)\n",
        "\n",
        "      yield {\n",
        "          'cid': cid,\n",
        "          'input': {\n",
        "              'text': {\n",
        "                'input_ids': text_ids,\n",
        "                'attention_mask': text_mask,\n",
        "              },\n",
        "              'molecule' : {\n",
        "                    'mol2vec' : np.fromstring(self.mols[cid], sep = \" \"),\n",
        "                    'cid' : cid\n",
        "              },\n",
        "          },\n",
        "          'label': label\n",
        "      }\n",
        "\n",
        "\n",
        "  def generate_examples_val(self):\n",
        "    \"\"\"Yields examples.\"\"\"\n",
        "\n",
        "    np.random.shuffle(self.validation_cids)\n",
        "\n",
        "    for cid in self.validation_cids:\n",
        "      label = np.random.randint(2)\n",
        "      rand_cid = np.random.choice(self.validation_cids)\n",
        "      if label:\n",
        "        text_input = self.text_tokenizer(self.descriptions[cid], truncation=True, max_length=self.text_trunc_length - 1,\n",
        "                                        padding='max_length', return_tensors = 'np')\n",
        "      else:\n",
        "        text_input = self.text_tokenizer(self.descriptions[rand_cid], truncation=True, max_length=self.text_trunc_length - 1,\n",
        "                                        padding='max_length', return_tensors = 'np')\n",
        "\n",
        "\n",
        "      text_ids = self.padarray(text_input['input_ids'].squeeze(), self.text_trunc_length)\n",
        "      text_mask = self.padarray(text_input['attention_mask'].squeeze(), self.text_trunc_length)\n",
        "\n",
        "      yield {\n",
        "          'cid': cid,\n",
        "          'input': {\n",
        "              'text': {\n",
        "                'input_ids': text_ids,\n",
        "                'attention_mask': text_mask,\n",
        "              },\n",
        "              'molecule' : {\n",
        "                    'mol2vec' : np.fromstring(self.mols[cid], sep = \" \"),\n",
        "                    'cid' : cid\n",
        "              },\n",
        "          },\n",
        "          'label': label\n",
        "      }\n",
        "\n",
        "  def generate_examples_test(self):\n",
        "    \"\"\"Yields examples.\"\"\"\n",
        "\n",
        "    np.random.shuffle(self.test_cids)\n",
        "\n",
        "    for cid in self.test_cids:\n",
        "      label = np.random.randint(2)\n",
        "      rand_cid = np.random.choice(self.test_cids)\n",
        "      if label:\n",
        "        text_input = self.text_tokenizer(self.descriptions[cid], truncation=True, max_length=self.text_trunc_length - 1,\n",
        "                                        padding='max_length', return_tensors = 'np')\n",
        "      else:\n",
        "        text_input = self.text_tokenizer(self.descriptions[rand_cid], truncation=True, max_length=self.text_trunc_length - 1,\n",
        "                                        padding='max_length', return_tensors = 'np')\n",
        "\n",
        "\n",
        "      text_ids = self.padarray(text_input['input_ids'].squeeze(), self.text_trunc_length)\n",
        "      text_mask = self.padarray(text_input['attention_mask'].squeeze(), self.text_trunc_length)\n",
        "\n",
        "      yield {\n",
        "          'cid': cid,\n",
        "          'input': {\n",
        "              'text': {\n",
        "                'input_ids': text_ids,\n",
        "                'attention_mask': text_mask,\n",
        "              },\n",
        "              'molecule' : {\n",
        "                    'mol2vec' : np.fromstring(self.mols[cid], sep = \" \"),\n",
        "                    'cid' : cid\n",
        "              },\n",
        "          },\n",
        "          'label': label\n",
        "      }\n",
        "\n",
        "mounted_path_token_embs = data_path + \"token_embedding_dict.npy\"\n",
        "mounted_path_train = data_path + \"training.txt\"\n",
        "mounted_path_val = data_path + \"val.txt\"\n",
        "mounted_path_test = data_path + \"test.txt\"\n",
        "mounted_path_molecules = data_path + \"ChEBI_defintions_substructure_corpus.cp\"\n",
        "\n",
        "gt = GenerateData(mounted_path_train, mounted_path_val, mounted_path_test,\n",
        "                  mounted_path_molecules, mounted_path_token_embs,\n",
        "                  ablation_1 = ABLATION_1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zck-zGTa8JOv"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "  'Characterizes a dataset for PyTorch'\n",
        "  def __init__(self, gen, length):\n",
        "      'Initialization'\n",
        "\n",
        "      self.gen = gen\n",
        "      self.it = iter(self.gen())\n",
        "\n",
        "      self.length = length\n",
        "\n",
        "  def __len__(self):\n",
        "      'Denotes the total number of samples'\n",
        "      return self.length\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      'Generates one sample of data'\n",
        "\n",
        "      try:\n",
        "        ex = next(self.it)\n",
        "      except StopIteration:\n",
        "        self.it = iter(self.gen())\n",
        "        ex = next(self.it)\n",
        "\n",
        "      X = ex['input']\n",
        "      y = ex['label']\n",
        "\n",
        "      return X, y\n",
        "\n",
        "training_set = Dataset(gt.generate_examples_train, len(gt.training_cids))\n",
        "validation_set = Dataset(gt.generate_examples_val, len(gt.validation_cids))\n",
        "test_set = Dataset(gt.generate_examples_test, len(gt.test_cids))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Fj8h8vhk3W0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Parameters\n",
        "params = {'batch_size': gt.batch_size,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 1}\n",
        "\n",
        "training_generator = DataLoader(training_set, **params)\n",
        "validation_generator = DataLoader(validation_set, **params)\n",
        "test_generator = DataLoader(test_set, **params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MVm3jz5pIcf"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MoleculeGraphDataset(GeoDataset):\n",
        "    def __init__(self, root, cids, data_path, gt, transform=None, pre_transform=None):\n",
        "        self.cids = cids\n",
        "        self.data_path = data_path\n",
        "        self.gt = gt\n",
        "        super(MoleculeGraphDataset, self).__init__(root, transform, pre_transform)\n",
        "\n",
        "        self.idx_to_cid = {}\n",
        "        i = 0\n",
        "        for raw_path in self.raw_paths:\n",
        "            cid = int(raw_path.split('/')[-1][:-6])\n",
        "            self.idx_to_cid[i] = cid\n",
        "            i += 1\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return [cid + \".graph\" for cid in self.cids]\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['data_{}.pt'.format(cid) for cid in self.cids]\n",
        "\n",
        "    def download(self):\n",
        "        # Download to `self.raw_dir`.\n",
        "        shutil.copy(self.data_path, os.path.join(self.raw_dir, \"/mol_graphs.zip\"))\n",
        "\n",
        "    def process_graph(self, raw_path):\n",
        "      edge_index  = []\n",
        "      x = []\n",
        "      with open(raw_path, 'r') as f:\n",
        "        next(f)\n",
        "        for line in f: #edges\n",
        "          if line != \"\\n\":\n",
        "            edge = *map(int, line.split()),\n",
        "            edge_index.append(edge)\n",
        "          else:\n",
        "            break\n",
        "        next(f)\n",
        "        for line in f: #get mol2vec features:\n",
        "          substruct_id = line.strip().split()[-1]\n",
        "          if substruct_id in self.gt.token_embs:\n",
        "            x.append(self.gt.token_embs[substruct_id])\n",
        "          else:\n",
        "            x.append(self.gt.token_embs['UNK'])\n",
        "\n",
        "        return torch.LongTensor(edge_index).T, torch.FloatTensor(x)\n",
        "\n",
        "\n",
        "\n",
        "    def process(self):\n",
        "\n",
        "        with zipfile.ZipFile(os.path.join(self.raw_dir, \"/mol_graphs.zip\"), 'r') as zip_ref:\n",
        "            zip_ref.extractall(self.raw_dir)\n",
        "\n",
        "\n",
        "        i = 0\n",
        "        for raw_path in self.raw_paths:\n",
        "            # Read data from `raw_path`.\n",
        "\n",
        "            cid = int(raw_path.split('/')[-1][:-6])\n",
        "\n",
        "            edge_index, x = self.process_graph(raw_path)\n",
        "            data = Data(x=x, edge_index = edge_index)\n",
        "\n",
        "            if self.pre_filter is not None and not self.pre_filter(data):\n",
        "                continue\n",
        "\n",
        "            if self.pre_transform is not None:\n",
        "                data = self.pre_transform(data)\n",
        "\n",
        "            torch.save(data, osp.join(self.processed_dir, 'data_{}.pt'.format(cid)))\n",
        "            i += 1\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.processed_file_names)\n",
        "\n",
        "    def get(self, idx):\n",
        "        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(self.idx_to_cid[idx])))\n",
        "        return data\n",
        "\n",
        "    def get_cid(self, cid):\n",
        "        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(cid)))\n",
        "        return data\n",
        "\n",
        "#To get specific lists...\n",
        "\n",
        "class CustomGraphCollater(object):\n",
        "    def __init__(self, dataset, mask_len, follow_batch = [], exclude_keys = []):\n",
        "        self.follow_batch = follow_batch\n",
        "        self.exclude_keys = exclude_keys\n",
        "        self.dataset = dataset\n",
        "        self.mask_len = mask_len\n",
        "        self.mask_indices = np.array(range(mask_len))\n",
        "\n",
        "    def generate_mask(self, sz):\n",
        "        rv = torch.zeros((self.mask_len), dtype = torch.bool)\n",
        "        rv = rv.masked_fill(torch.BoolTensor(self.mask_indices < sz), bool(1)) #pytorch transformer input version\n",
        "        rv[-1] = 0 #set last value to 0 because pytorch can't handle all 1s\n",
        "        return rv\n",
        "\n",
        "    def get_masks(self, batch):\n",
        "      return torch.stack([self.generate_mask(b.x.shape[0]) for b in batch])\n",
        "\n",
        "    def collate(self, batch):\n",
        "        elem = batch[0]\n",
        "        if isinstance(elem, Data):\n",
        "            return Batch.from_data_list(batch)\n",
        "\n",
        "        raise TypeError('DataLoader found invalid type: {}'.format(type(elem)))\n",
        "\n",
        "    def __call__(self, cids):\n",
        "\n",
        "        tmp = [self.dataset.get_cid(int(cid)) for cid in cids]\n",
        "        return self.collate(tmp), self.get_masks(tmp)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkfbSCMipLbW"
      },
      "outputs": [],
      "source": [
        "root = 'graph-data/'\n",
        "graph_data_path = local_path + \"/data/mol_graphs.zip\"\n",
        "\n",
        "\n",
        "mg_data_tr = MoleculeGraphDataset(root, gt.training_cids, graph_data_path, gt)\n",
        "graph_batcher_tr = CustomGraphCollater(mg_data_tr, gt.mol_trunc_length)\n",
        "\n",
        "mg_data_val = MoleculeGraphDataset(root, gt.validation_cids, graph_data_path, gt)\n",
        "graph_batcher_val = CustomGraphCollater(mg_data_val, gt.mol_trunc_length)\n",
        "\n",
        "mg_data_test = MoleculeGraphDataset(root, gt.test_cids, graph_data_path, gt)\n",
        "graph_batcher_test = CustomGraphCollater(mg_data_test, gt.mol_trunc_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aksj743St9ga"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ATTNModel(nn.Module):\n",
        "\n",
        "    def __init__(self, ntoken, ninp, nout, nhid, nhead, nlayers,\n",
        "                 graph_hidden_channels, mol_trunc_length,  dropout=0.5,\n",
        "                 ablation_1 = False, ablation_2 = False, ablation_3 = False,\n",
        "                 ablation_4 = False, ablation_5 = False):\n",
        "        super(ATTNModel, self).__init__()\n",
        "\n",
        "        self.text_hidden1 = nn.Linear(ninp, nhid)\n",
        "        self.text_hidden2 = nn.Linear(nhid, nout)\n",
        "\n",
        "        self.ninp = ninp\n",
        "        self.nhid = nhid\n",
        "        self.nout = nout\n",
        "        self.graph_hidden_channels = graph_hidden_channels\n",
        "\n",
        "        self.drop = nn.Dropout(p=dropout)\n",
        "\n",
        "        # This could be a list, but the code is simpler to read using\n",
        "        # discrete variables\n",
        "        self.ablation_1 = ablation_1 # BERT not SciBert\n",
        "        self.ablation_2 = ablation_2 # Remove temperature\n",
        "        self.ablation_3 = ablation_3 # Remove negative sampling\n",
        "        self.ablation_4 = ablation_4 # One token per atom?\n",
        "        self.ablation_5 = ablation_5 # Remove layer norm\n",
        "\n",
        "        decoder_layers = TransformerDecoderLayer(ninp, nhead, nhid, dropout)\n",
        "        self.text_transformer_decoder = TransformerDecoder(decoder_layers,\n",
        "                                                           nlayers)\n",
        "\n",
        "        if not self.ablation_2:\n",
        "          self.temp = nn.Parameter(torch.Tensor([0.07]))\n",
        "          self.register_parameter( 'temp' , self.temp )\n",
        "\n",
        "        if not self.ablation_5:\n",
        "          self.ln1 = nn.LayerNorm((nout))\n",
        "          self.ln2 = nn.LayerNorm((nout))\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.selu = nn.SELU()\n",
        "\n",
        "        #For GCN:\n",
        "        self.conv1 = GCNConv(mg_data_val.num_node_features,\n",
        "                             graph_hidden_channels)\n",
        "        self.conv2 = GCNConv(graph_hidden_channels, graph_hidden_channels)\n",
        "        self.conv3 = GCNConv(graph_hidden_channels, graph_hidden_channels)\n",
        "        self.mol_hidden1 = nn.Linear(graph_hidden_channels, nhid)\n",
        "        self.mol_hidden2 = nn.Linear(nhid, nout)\n",
        "\n",
        "\n",
        "        self.other_params = list(self.parameters()) #get all but bert params\n",
        "        if self.ablation_1:\n",
        "          self.text_transformer_model = BertModel.from_pretrained(\"google-bert/bert-base-uncased\")\n",
        "        else:\n",
        "          self.text_transformer_model = BertModel.from_pretrained('allenai/scibert_scivocab_uncased')\n",
        "\n",
        "        #self.text_transformer_model = BertModel.from_pretrained(\"google-bert/bert-base-uncased\")\n",
        "        self.text_transformer_model.train()\n",
        "\n",
        "        self.device = 'cpu'\n",
        "\n",
        "    def set_device(self, dev):\n",
        "        self.to(dev)\n",
        "        self.device = dev\n",
        "\n",
        "    def forward(self, text, graph_batch, text_mask = None, molecule_mask = None):\n",
        "\n",
        "        text_encoder_output = self.text_transformer_model(text, attention_mask = text_mask)\n",
        "\n",
        "        #Obtain node embeddings\n",
        "        x = graph_batch.x\n",
        "        edge_index = graph_batch.edge_index\n",
        "        batch = graph_batch.batch\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        mol_x = self.conv3(x, edge_index)\n",
        "\n",
        "        #turn pytorch geometric output into the correct format for transformer\n",
        "        #requires recovering the nodes from each graph into a separate dimension\n",
        "        node_features = torch.zeros((graph_batch.num_graphs, gt.mol_trunc_length,\n",
        "                                     self.graph_hidden_channels)).to(self.device)\n",
        "        for i, p in enumerate(graph_batch.ptr):\n",
        "          if p == 0:\n",
        "            old_p = p\n",
        "            continue\n",
        "          node_features[i - 1, :p-old_p, :] = mol_x[old_p:torch.min(p, old_p + gt.mol_trunc_length), :]\n",
        "          old_p = p\n",
        "        node_features = torch.transpose(node_features, 0, 1)\n",
        "\n",
        "        text_output = self.text_transformer_decoder(text_encoder_output['last_hidden_state'].transpose(0,1), node_features,\n",
        "                                                            tgt_key_padding_mask = text_mask == 0, memory_key_padding_mask = ~molecule_mask)\n",
        "\n",
        "\n",
        "        #Readout layer\n",
        "        x = global_mean_pool(mol_x, batch)  # [batch_size, graph_hidden_channels]\n",
        "\n",
        "        x = self.mol_hidden1(x)\n",
        "        x = x.relu()\n",
        "        x = self.mol_hidden2(x)\n",
        "\n",
        "        text_x = torch.tanh(self.text_hidden1(text_output[0,:,:])) #[CLS] pooler\n",
        "        text_x = self.text_hidden2(text_x)\n",
        "\n",
        "        if not self.ablation_5:\n",
        "          x = self.ln1(x)\n",
        "          text_x = self.ln2(text_x)\n",
        "\n",
        "        if not self.ablation_2:\n",
        "          x = x * torch.exp(self.temp)\n",
        "          text_x = text_x * torch.exp(self.temp)\n",
        "\n",
        "        return text_x, x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGMF8AZcB2Zy"
      },
      "outputs": [],
      "source": [
        "model = ATTNModel(ntoken = gt.text_tokenizer.vocab_size, ninp = 768, nout = 300,\n",
        "              nhead = 8, nhid = 512, nlayers = 3,\n",
        "              mol_trunc_length = gt.mol_trunc_length,\n",
        "              graph_hidden_channels = 768, ablation_1 = ABLATION_1,\n",
        "              ablation_2 = ABLATION_2, ablation_3 = ABLATION_3,\n",
        "              ablation_4 = ABLATION_4, ablation_5 = ABLATION_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9eP2y9dbw32"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from transformers.optimization import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 40\n",
        "init_lr = 1e-4\n",
        "bert_lr = 3e-5\n",
        "bert_params = list(model.text_transformer_model.parameters())\n",
        "\n",
        "optimizer = optim.Adam([\n",
        "                {'params': model.other_params},\n",
        "                {'params': bert_params, 'lr': bert_lr}\n",
        "            ], lr=init_lr)\n",
        "\n",
        "num_warmup_steps = 1000\n",
        "num_training_steps = epochs * len(training_generator) - num_warmup_steps\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = num_warmup_steps,\n",
        "                                            num_training_steps = num_training_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1heECu1nVRB"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)\n",
        "\n",
        "tmp = model.set_device(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HytSaAyHNBuZ"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "def loss_func(v1, v2, labels):\n",
        "  logits = torch.matmul(v1,torch.transpose(v2, 0, 1))\n",
        "  eye = torch.diag_embed(labels).to(device)\n",
        "  return criterion(logits, eye) + criterion(torch.transpose(logits, 0, 1), eye), logits.diag() > 0\n",
        "\n",
        "CE = nn.CrossEntropyLoss()\n",
        "\n",
        "def contrastive_loss(v1, v2):\n",
        "  logits = torch.matmul(v1,torch.transpose(v2, 0, 1))\n",
        "  labels = torch.arange(logits.shape[0], device=v1.device)\n",
        "  return CE(logits, labels) + CE(torch.transpose(logits, 0, 1), labels)\n",
        "\n",
        "def info_nce_loss(v1, v2, labels, temperature=0.5):\n",
        "  \"\"\"\n",
        "  InfoNCE loss function for contrastive learning.\n",
        "\n",
        "  Args:\n",
        "      v1: Tensor of embeddings from the first view (shape: batch_size, embedding_dim).\n",
        "      v2: Tensor of embeddings from the second view (shape: batch_size, embedding_dim).\n",
        "      labels: Tensor of labels indicating similar pairs (shape: batch_size).\n",
        "      temperature: Hyperparameter controlling the influence of dissimilar pairs (default: 0.5).\n",
        "\n",
        "  Returns:\n",
        "      loss: Tensor containing the contrastive estimation loss.\n",
        "  \"\"\"\n",
        "\n",
        "  batch_size = v1.size(0)\n",
        "  # Normalize embeddings for stability\n",
        "  v1_normalized = nn.functional.normalize(v1, dim=1)\n",
        "  v2_normalized = nn.functional.normalize(v2, dim=1)\n",
        "\n",
        "  # Dot product similarity scores\n",
        "  logits = torch.matmul(v1_normalized, torch.transpose(v2_normalized, 0, 1))\n",
        "\n",
        "  # Separate positive and negative scores based on labels\n",
        "  positive_scores = torch.masked_select(logits, labels.view(batch_size, 1).expand_as(logits))\n",
        "  negative_scores = torch.masked_select(logits, ~labels.view(batch_size, 1).expand_as(logits))\n",
        "\n",
        "  # Compute InfoNCE loss with temperature\n",
        "  loss = -torch.mean(torch.log(torch.exp(positive_scores / temperature) /\n",
        "                             torch.sum(torch.exp(logits / temperature), dim=1)))\n",
        "  return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtfDFAnN_Neu"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "train_acc = []\n",
        "val_acc = []\n",
        "\n",
        "\n",
        "\n",
        "# Loop over epochs\n",
        "for epoch in range(epochs):\n",
        "    # Training\n",
        "\n",
        "    start_time = time.time()\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    model.train()\n",
        "    for i, d in enumerate(training_generator):\n",
        "        batch, labels = d\n",
        "        # Transfer to GPU\n",
        "\n",
        "        text = batch['text']['input_ids'].to(device)\n",
        "        text_mask = batch['text']['attention_mask'].bool().to(device)\n",
        "        graph_batch, molecule_mask = graph_batcher_tr(d[0]['molecule']['cid'])\n",
        "        graph_batch = graph_batch.to(device)\n",
        "        molecule_mask = molecule_mask.to(device)\n",
        "\n",
        "\n",
        "        labels = labels.float().to(device)\n",
        "\n",
        "        text_out, chem_out = model(text, graph_batch, text_mask, molecule_mask)\n",
        "        if ABLATION_3:\n",
        "          loss, pred = info_nce_loss(text_out, chem_out, labels)\n",
        "        else:\n",
        "          loss, pred = loss_func(text_out, chem_out, labels)\n",
        "        if torch.isnan(loss): zz\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_acc += np.sum((pred.squeeze().cpu().detach().numpy() > 0) == labels.cpu().detach().numpy()) / labels.shape[0]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "          print(i+1, \"batches trained. Avg loss:\\t\", running_loss / (i+1),\n",
        "                \"Acc:\", str(running_acc / (i+1)), \". Avg ms/step =\",\n",
        "                1000*(time.time()-start_time)/(i+1))\n",
        "    train_losses.append(running_loss / (i+1))\n",
        "    train_acc.append(running_acc / (i+1))\n",
        "\n",
        "    print(\"Epoch\", epoch, \"training loss:\\t\\t\", running_loss / (i+1),\n",
        "          \". Time =\", (time.time()-start_time), \"seconds.\")\n",
        "    print(\"Training accuracy:\", train_acc[-1])\n",
        "\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.set_grad_enabled(False):\n",
        "      start_time = time.time()\n",
        "      running_acc = 0.0\n",
        "      running_loss = 0.0\n",
        "      for i, d in enumerate(validation_generator):\n",
        "          batch, labels = d\n",
        "          # Transfer to GPU\n",
        "\n",
        "          text = batch['text']['input_ids'].to(device)\n",
        "          text_mask = batch['text']['attention_mask'].bool().to(device)\n",
        "          graph_batch, molecule_mask = graph_batcher_val(d[0]['molecule']['cid'])\n",
        "          graph_batch = graph_batch.to(device)\n",
        "          molecule_mask = molecule_mask.to(device)\n",
        "\n",
        "          labels = labels.float().to(device)\n",
        "\n",
        "          text_out, chem_out = model(text, graph_batch, text_mask, molecule_mask)\n",
        "          loss, pred = loss_func(text_out, chem_out, labels)\n",
        "\n",
        "          running_loss += loss.item()\n",
        "          running_acc += np.sum((pred.squeeze().cpu().detach().numpy() > 0) == labels.cpu().detach().numpy()) / labels.shape[0]\n",
        "\n",
        "\n",
        "          if (i+1) % 100 == 0: print(i+1, \"batches eval. Avg loss:\\t\",\n",
        "                                     running_loss / (i+1), \". Avg ms/step =\",\n",
        "                                     1000*(time.time()-start_time)/(i+1))\n",
        "      val_losses.append(running_loss / (i+1))\n",
        "      val_acc.append(running_acc / (i+1))\n",
        "\n",
        "\n",
        "      min_loss = np.min(val_losses)\n",
        "      if val_losses[-1] == min_loss:\n",
        "          torch.save(model.state_dict(), output_path + 'weights_pretrained.{epoch:02d}-{min_loss:.2f}.pt'.format(epoch = epoch, min_loss = min_loss))\n",
        "\n",
        "    print(\"Epoch\", epoch, \"validation loss:\\t\", running_loss / (i+1), \". Time =\", (time.time()-start_time), \"seconds.\")\n",
        "    print(\"Validation accuracy:\", val_acc[-1])\n",
        "\n",
        "torch.save(model.state_dict(), output_path + \"final_weights.\"+str(epochs)+\".pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYHuY5GkbmfK"
      },
      "source": [
        "#Extract attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDmzJpf8boQS"
      },
      "outputs": [],
      "source": [
        "last_decoder = model.text_transformer_decoder.layers[-1]\n",
        "\n",
        "mha_weights = {}\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        mha_weights[cid] = output[1].cpu().detach().numpy()\n",
        "    return hook\n",
        "\n",
        "\n",
        "handle = last_decoder.multihead_attn.register_forward_hook(get_activation(''))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def patch_attention(m):\n",
        "    forward_orig = m.forward\n",
        "\n",
        "    def wrap(*args, **kwargs):\n",
        "        kwargs[\"need_weights\"] = True\n",
        "        kwargs[\"average_attn_weights\"] = True\n",
        "\n",
        "        return forward_orig(*args, **kwargs)\n",
        "\n",
        "    m.forward = wrap\n",
        "\n",
        "\n",
        "class SaveOutput:\n",
        "    def __init__(self):\n",
        "        self.outputs = []\n",
        "\n",
        "    def __call__(self, module, module_in, module_out):\n",
        "        self.outputs.append(module_out[1])\n",
        "\n",
        "    def clear(self):\n",
        "        self.outputs = []\n",
        "\n",
        "patch_attention(model.text_transformer_decoder.layers[-1].multihead_attn)"
      ],
      "metadata": {
        "id": "u4TMbzWPKb8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVRbgPCZbsN1"
      },
      "outputs": [],
      "source": [
        "for i,d in enumerate(gt.generate_examples_train()):\n",
        "\n",
        "  batch = d['input']\n",
        "\n",
        "  cid = d['cid']#batch['molecule']['cid'][0]\n",
        "  text_mask = torch.Tensor(batch['text']['attention_mask']).bool().reshape(1,-1).to(device)\n",
        "\n",
        "  text = torch.Tensor(batch['text']['input_ids']).int().reshape(1,-1).to(device)\n",
        "  graph_batch, molecule_mask = graph_batcher_val([batch['molecule']['cid']])\n",
        "  graph_batch = graph_batch.to(device)\n",
        "  molecule_mask = molecule_mask.to(device)\n",
        "  graph_batch.edge_index = graph_batch.edge_index.reshape((2,-1))\n",
        "\n",
        "  out = model(text, graph_batch, text_mask, molecule_mask)\n",
        "\n",
        "  #for memory reasons\n",
        "  mol_length = graph_batch.x.shape[0]\n",
        "  text_input = gt.text_tokenizer(gt.descriptions[cid], truncation=True, padding = 'max_length',\n",
        "                                    max_length=gt.text_trunc_length - 1)\n",
        "  text_length = np.sum(text_input['attention_mask'])\n",
        "\n",
        "  mha_weights[cid] = mha_weights[cid][0,:text_length, :mol_length]\n",
        "\n",
        "  if (i+1) % 1000 == 0: print(i+1)\n",
        "\n",
        "for i,d in enumerate(gt.generate_examples_val()):\n",
        "\n",
        "  batch = d['input']\n",
        "\n",
        "  cid = d['cid']#batch['molecule']['cid'][0]\n",
        "  text_mask = torch.Tensor(batch['text']['attention_mask']).bool().reshape(1,-1).to(device)\n",
        "\n",
        "  text = torch.Tensor(batch['text']['input_ids']).int().reshape(1,-1).to(device)\n",
        "  graph_batch, molecule_mask = graph_batcher_val([batch['molecule']['cid']])\n",
        "  graph_batch = graph_batch.to(device)\n",
        "  molecule_mask = molecule_mask.to(device)\n",
        "  graph_batch.edge_index = graph_batch.edge_index.reshape((2,-1))\n",
        "\n",
        "\n",
        "  out = model(text, graph_batch, text_mask, molecule_mask)\n",
        "\n",
        "  #for memory reasons\n",
        "  mol_length = graph_batch.x.shape[0]\n",
        "  text_input = gt.text_tokenizer(gt.descriptions[cid], truncation=True, padding = 'max_length',\n",
        "                                    max_length=gt.text_trunc_length - 1)\n",
        "  text_length = np.sum(text_input['attention_mask'])\n",
        "  mha_weights[cid] = mha_weights[cid][0,:text_length, :mol_length]\n",
        "\n",
        "\n",
        "  if (i+1) % 1000 == 0: print(i+1)\n",
        "\n",
        "for i,d in enumerate(gt.generate_examples_test()):\n",
        "\n",
        "  batch = d['input']\n",
        "\n",
        "  cid = d['cid']\n",
        "  text_mask = torch.Tensor(batch['text']['attention_mask']).bool().reshape(1,-1).to(device)\n",
        "\n",
        "  text = torch.Tensor(batch['text']['input_ids']).int().reshape(1,-1).to(device)\n",
        "  graph_batch, molecule_mask = graph_batcher_test([batch['molecule']['cid']])\n",
        "  graph_batch = graph_batch.to(device)\n",
        "  molecule_mask = molecule_mask.to(device)\n",
        "  graph_batch.edge_index = graph_batch.edge_index.reshape((2,-1))\n",
        "\n",
        "\n",
        "  out = model(text, graph_batch, text_mask, molecule_mask)\n",
        "\n",
        "  #for memory reasons\n",
        "  mol_length = graph_batch.x.shape[0]\n",
        "  text_input = gt.text_tokenizer(gt.descriptions[cid], truncation=True, padding = 'max_length',\n",
        "                                    max_length=gt.text_trunc_length - 1)\n",
        "  text_length = np.sum(text_input['attention_mask'])\n",
        "  mha_weights[cid] = mha_weights[cid][0,:text_length, :mol_length]\n",
        "\n",
        "\n",
        "  if (i+1) % 1000 == 0: print(i+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKRm1JIGbzE6"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(output_path + \"mha_weights.pkl\", 'wb') as fp:\n",
        "  pickle.dump(mha_weights, fp)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}