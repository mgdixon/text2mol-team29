{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgdixon/text2mol-team29/blob/main/ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Install Cloud Storage FUSE.\n",
        "!echo \"deb https://packages.cloud.google.com/apt gcsfuse-`lsb_release -c -s` main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "!apt -qq update && apt -qq install gcsfuse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "691XGKhFQBpT",
        "outputId": "53cb0acb-6b37-40b2-ac6a-ab9293050f78"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deb https://packages.cloud.google.com/apt gcsfuse-jammy main\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2659  100  2659    0     0  53085      0 --:--:-- --:--:-- --:--:-- 53180\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "OK\n",
            "50 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mhttps://packages.cloud.google.com/apt/dists/gcsfuse-jammy/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\u001b[0m\n",
            "The following NEW packages will be installed:\n",
            "  gcsfuse\n",
            "0 upgraded, 1 newly installed, 0 to remove and 50 not upgraded.\n",
            "Need to get 10.4 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Selecting previously unselected package gcsfuse.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../gcsfuse_2.0.1_amd64.deb ...\n",
            "Unpacking gcsfuse (2.0.1) ...\n",
            "Setting up gcsfuse (2.0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount a Cloud Storage bucket or location, without the gs:// prefix.\n",
        "mount_path = \"team29-text2mol\"  # or a location like \"my-bucket/path/to/mount\"\n",
        "local_path = f\"/mnt/gs/{mount_path}\"\n",
        "\n",
        "!mkdir -p {local_path}\n",
        "!gcsfuse --implicit-dirs {mount_path} {local_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gzQsr8UQEZX",
        "outputId": "e810cc94-16c6-483a-e2eb-3d3fad7ec877"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"timestamp\":{\"seconds\":1714414812,\"nanos\":55706918},\"severity\":\"INFO\",\"message\":\"Start gcsfuse/2.0.1 (Go version go1.22.1) for app \\\"\\\" using mount point: /mnt/gs/team29-text2mol\\n\"}\n",
            "{\"timestamp\":{\"seconds\":1714414812,\"nanos\":56474158},\"severity\":\"INFO\",\"message\":\"GCSFuse mount command flags: {\\\"AppName\\\":\\\"\\\",\\\"Foreground\\\":false,\\\"ConfigFile\\\":\\\"\\\",\\\"MountOptions\\\":{},\\\"DirMode\\\":493,\\\"FileMode\\\":420,\\\"Uid\\\":-1,\\\"Gid\\\":-1,\\\"ImplicitDirs\\\":true,\\\"OnlyDir\\\":\\\"\\\",\\\"RenameDirLimit\\\":0,\\\"CustomEndpoint\\\":null,\\\"BillingProject\\\":\\\"\\\",\\\"KeyFile\\\":\\\"\\\",\\\"TokenUrl\\\":\\\"\\\",\\\"ReuseTokenFromUrl\\\":true,\\\"EgressBandwidthLimitBytesPerSecond\\\":-1,\\\"OpRateLimitHz\\\":-1,\\\"SequentialReadSizeMb\\\":200,\\\"MaxRetrySleep\\\":30000000000,\\\"StatCacheCapacity\\\":20460,\\\"StatCacheTTL\\\":60000000000,\\\"TypeCacheTTL\\\":60000000000,\\\"HttpClientTimeout\\\":0,\\\"MaxRetryDuration\\\":-1000000000,\\\"RetryMultiplier\\\":2,\\\"LocalFileCache\\\":false,\\\"TempDir\\\":\\\"\\\",\\\"ClientProtocol\\\":\\\"http1\\\",\\\"MaxConnsPerHost\\\":100,\\\"MaxIdleConnsPerHost\\\":100,\\\"EnableNonexistentTypeCache\\\":false,\\\"StackdriverExportInterval\\\":0,\\\"OtelCollectorAddress\\\":\\\"\\\",\\\"LogFile\\\":\\\"\\\",\\\"LogFormat\\\":\\\"json\\\",\\\"ExperimentalEnableJsonRead\\\":false,\\\"DebugFuseErrors\\\":true,\\\"DebugFuse\\\":false,\\\"DebugFS\\\":false,\\\"DebugGCS\\\":false,\\\"DebugHTTP\\\":false,\\\"DebugInvariants\\\":false,\\\"DebugMutex\\\":false}\"}\n",
            "{\"timestamp\":{\"seconds\":1714414812,\"nanos\":56679988},\"severity\":\"INFO\",\"message\":\"GCSFuse mount config flags: {\\\"CreateEmptyFile\\\":false,\\\"Severity\\\":\\\"INFO\\\",\\\"Format\\\":\\\"json\\\",\\\"FilePath\\\":\\\"\\\",\\\"LogRotateConfig\\\":{\\\"MaxFileSizeMB\\\":512,\\\"BackupFileCount\\\":10,\\\"Compress\\\":true},\\\"MaxSizeMB\\\":-1,\\\"CacheFileForRangeRead\\\":false,\\\"CacheDir\\\":\\\"\\\",\\\"TtlInSeconds\\\":-9223372036854775808,\\\"TypeCacheMaxSizeMB\\\":4,\\\"StatCacheMaxSizeMB\\\":-9223372036854775808,\\\"EnableEmptyManagedFolders\\\":false,\\\"ConnPoolSize\\\":1}\"}\n",
            "{\"timestamp\":{\"seconds\":1714414812,\"nanos\":604502631},\"severity\":\"INFO\",\"message\":\"File system has been successfully mounted.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Then you can access it like a local path.\n",
        "!ls -lh {local_path}/MLP_outputs/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZorYfr9QIXA",
        "outputId": "7a5d33df-1d7d-4fda-eca8-b5bbfd3f67e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 7.5G\n",
            "drwxr-xr-x 1 root root    0 Apr 29 18:20 embeddings\n",
            "-rw-r--r-- 1 root root 424M Apr  8 03:59 final_weights.40.pt\n",
            "-rw-r--r-- 1 root root 424M Apr  8 00:46 weights_pretrained.00-1.60.pt\n",
            "-rw-r--r-- 1 root root 424M Apr  8 00:51 weights_pretrained.01-0.65.pt\n",
            "-rw-r--r-- 1 root root 424M Apr  8 00:57 weights_pretrained.02-0.64.pt\n",
            "-rw-r--r-- 1 root root 424M Apr  8 01:03 weights_pretrained.03-0.55.pt\n",
            "-rw-r--r-- 1 root root 424M Apr  8 01:08 weights_pretrained.04-0.48.pt\n",
            "-rw-r--r-- 1 root root 424M Apr  8 01:14 weights_pretrained.05-0.40.pt\n",
            "-rw-r--r-- 1 root root 424M Apr  8 01:19 weights_pretrained.06-0.33.pt\n",
            "-rw-r--r-- 1 root root 424M Apr  8 01:29 weights_pretrained.08-0.32.pt\n",
            "-rw-r--r-- 1 root root 424M Apr  8 01:35 weights_pretrained.09-0.28.pt\n",
            "-rw-r--r-- 1 root root 424M Apr  8 01:45 weights_pretrained.11-0.27.pt\n",
            "-rw-r--r-- 1 root root 424M Apr  8 01:50 weights_pretrained.12-0.27.pt\n",
            "-rw-r--r-- 1 root root 424M Apr  8 02:05 weights_pretrained.15-0.21.pt\n",
            "-rw-r--r-- 1 root root 424M Apr  8 02:11 weights_pretrained.16-0.20.pt\n",
            "-rw-r--r-- 1 root root 424M Apr  8 02:16 weights_pretrained.17-0.19.pt\n",
            "-rw-r--r-- 1 root root 424M Apr  8 02:44 weights_pretrained.23-0.18.pt\n",
            "-rw-r--r-- 1 root root 424M Apr  8 03:35 weights_pretrained.34-0.14.pt\n",
            "-rw-r--r-- 1 root root 424M Apr  8 03:40 weights_pretrained.35-0.14.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_XgTpm9ZxoN9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "G8MSZ5412kEU"
      },
      "outputs": [],
      "source": [
        "dir1 = local_path + \"/GCN_output/embeddings/\"\n",
        "dir2 = local_path + \"/GCN2/embeddings/\"\n",
        "dir3 = local_path + \"/GCN3/embeddings/\"\n",
        "dir4 = local_path + \"/MLP_outputs/embeddings/\"\n",
        "dir5 = local_path + \"/MLP2/embeddings/\"\n",
        "dir6 = local_path + \"/MLP3/embeddings/\"\n",
        "\n",
        "\n",
        "cids_train1 = np.load(dir1 + \"cids_train.npy\", allow_pickle=True)\n",
        "cids_val1 = np.load(dir1 + \"cids_val.npy\", allow_pickle=True)\n",
        "cids_test1 = np.load(dir1 + \"cids_test.npy\", allow_pickle=True)\n",
        "\n",
        "chem_embeddings_train1 = np.load(dir1 + \"chem_embeddings_train.npy\")\n",
        "chem_embeddings_val1 = np.load(dir1 + \"chem_embeddings_val.npy\")\n",
        "chem_embeddings_test1 = np.load(dir1 + \"chem_embeddings_test.npy\")\n",
        "text_embeddings_train1 = np.load(dir1 + \"text_embeddings_train.npy\")\n",
        "text_embeddings_val1 = np.load(dir1 + \"text_embeddings_val.npy\")\n",
        "text_embeddings_test1 = np.load(dir1 + \"text_embeddings_test.npy\")\n",
        "\n",
        "cids_train2 = np.load(dir2 + \"cids_train.npy\", allow_pickle=True)\n",
        "cids_val2 = np.load(dir2 + \"cids_val.npy\", allow_pickle=True)\n",
        "cids_test2 = np.load(dir2 + \"cids_test.npy\", allow_pickle=True)\n",
        "\n",
        "chem_embeddings_train2 = np.load(dir2 + \"chem_embeddings_train.npy\")\n",
        "chem_embeddings_val2 = np.load(dir2 + \"chem_embeddings_val.npy\")\n",
        "chem_embeddings_test2 = np.load(dir2 + \"chem_embeddings_test.npy\")\n",
        "text_embeddings_train2 = np.load(dir2 + \"text_embeddings_train.npy\")\n",
        "text_embeddings_val2 = np.load(dir2 + \"text_embeddings_val.npy\")\n",
        "text_embeddings_test2 = np.load(dir2 + \"text_embeddings_test.npy\")\n",
        "\n",
        "cids_train3 = np.load(dir3 + \"cids_train.npy\", allow_pickle=True)\n",
        "cids_val3 = np.load(dir3 + \"cids_val.npy\", allow_pickle=True)\n",
        "cids_test3 = np.load(dir3 + \"cids_test.npy\", allow_pickle=True)\n",
        "\n",
        "chem_embeddings_train3 = np.load(dir3 + \"chem_embeddings_train.npy\")\n",
        "chem_embeddings_val3 = np.load(dir3 + \"chem_embeddings_val.npy\")\n",
        "chem_embeddings_test3 = np.load(dir3 + \"chem_embeddings_test.npy\")\n",
        "text_embeddings_train3 = np.load(dir3 + \"text_embeddings_train.npy\")\n",
        "text_embeddings_val3 = np.load(dir3 + \"text_embeddings_val.npy\")\n",
        "text_embeddings_test3 = np.load(dir3 + \"text_embeddings_test.npy\")\n",
        "\n",
        "cids_train4 = np.load(dir4 + \"cids_train.npy\", allow_pickle=True)\n",
        "cids_val4 = np.load(dir4 + \"cids_val.npy\", allow_pickle=True)\n",
        "cids_test4 = np.load(dir4 + \"cids_test.npy\", allow_pickle=True)\n",
        "\n",
        "chem_embeddings_train4 = np.load(dir4 + \"chem_embeddings_train.npy\")\n",
        "chem_embeddings_val4 = np.load(dir4 + \"chem_embeddings_val.npy\")\n",
        "chem_embeddings_test4 = np.load(dir4 + \"chem_embeddings_test.npy\")\n",
        "text_embeddings_train4 = np.load(dir4 + \"text_embeddings_train.npy\")\n",
        "text_embeddings_val4 = np.load(dir4 + \"text_embeddings_val.npy\")\n",
        "text_embeddings_test4 = np.load(dir4 + \"text_embeddings_test.npy\")\n",
        "\n",
        "cids_train5 = np.load(dir5 + \"cids_train.npy\", allow_pickle=True)\n",
        "cids_val5 = np.load(dir5 + \"cids_val.npy\", allow_pickle=True)\n",
        "cids_test5 = np.load(dir5 + \"cids_test.npy\", allow_pickle=True)\n",
        "\n",
        "chem_embeddings_train5 = np.load(dir5 + \"chem_embeddings_train.npy\")\n",
        "chem_embeddings_val5 = np.load(dir5 + \"chem_embeddings_val.npy\")\n",
        "chem_embeddings_test5 = np.load(dir5 + \"chem_embeddings_test.npy\")\n",
        "text_embeddings_train5 = np.load(dir5 + \"text_embeddings_train.npy\")\n",
        "text_embeddings_val5 = np.load(dir5 + \"text_embeddings_val.npy\")\n",
        "text_embeddings_test5 = np.load(dir5 + \"text_embeddings_test.npy\")\n",
        "\n",
        "cids_train6 = np.load(dir6 + \"cids_train.npy\", allow_pickle=True)\n",
        "cids_val6 = np.load(dir6 + \"cids_val.npy\", allow_pickle=True)\n",
        "cids_test6 = np.load(dir6 + \"cids_test.npy\", allow_pickle=True)\n",
        "\n",
        "chem_embeddings_train6 = np.load(dir6 + \"chem_embeddings_train.npy\")\n",
        "chem_embeddings_val6 = np.load(dir6 + \"chem_embeddings_val.npy\")\n",
        "chem_embeddings_test6 = np.load(dir6 + \"chem_embeddings_test.npy\")\n",
        "text_embeddings_train6 = np.load(dir6 + \"text_embeddings_train.npy\")\n",
        "text_embeddings_val6 = np.load(dir6 + \"text_embeddings_val.npy\")\n",
        "text_embeddings_test6 = np.load(dir6 + \"text_embeddings_test.npy\")\n",
        "\n",
        "#Reorder (this is very important):\n",
        "tmp = cids_train2.tolist()\n",
        "indexes = [tmp.index(i) for i in cids_train1]\n",
        "tmp = cids_val2.tolist()\n",
        "indexes_val = [tmp.index(i) for i in cids_val1]\n",
        "tmp = cids_test2.tolist()\n",
        "indexes_test = [tmp.index(i) for i in cids_test1]\n",
        "\n",
        "cids_train2 = cids_train2[indexes]\n",
        "cids_val2 = cids_val2[indexes_val]\n",
        "cids_test2 = cids_test2[indexes_test]\n",
        "\n",
        "chem_embeddings_train2 = chem_embeddings_train2[indexes]\n",
        "text_embeddings_train2 = text_embeddings_train2[indexes]\n",
        "chem_embeddings_val2 = chem_embeddings_val2[indexes_val]\n",
        "text_embeddings_val2 = text_embeddings_val2[indexes_val]\n",
        "chem_embeddings_test2 = chem_embeddings_test2[indexes_test]\n",
        "text_embeddings_test2 = text_embeddings_test2[indexes_test]\n",
        "\n",
        "\n",
        "tmp = cids_train3.tolist()\n",
        "indexes = [tmp.index(i) for i in cids_train1]\n",
        "tmp = cids_val3.tolist()\n",
        "indexes_val = [tmp.index(i) for i in cids_val1]\n",
        "tmp = cids_test3.tolist()\n",
        "indexes_test = [tmp.index(i) for i in cids_test1]\n",
        "\n",
        "cids_train3 = cids_train3[indexes]\n",
        "cids_val3 = cids_val3[indexes_val]\n",
        "cids_test3 = cids_test3[indexes_test]\n",
        "\n",
        "chem_embeddings_train3 = chem_embeddings_train3[indexes]\n",
        "text_embeddings_train3 = text_embeddings_train3[indexes]\n",
        "chem_embeddings_val3 = chem_embeddings_val3[indexes_val]\n",
        "text_embeddings_val3 = text_embeddings_val3[indexes_val]\n",
        "chem_embeddings_test3 = chem_embeddings_test3[indexes_test]\n",
        "text_embeddings_test3 = text_embeddings_test3[indexes_test]\n",
        "\n",
        "\n",
        "tmp = cids_train4.tolist()\n",
        "indexes = [tmp.index(i) for i in cids_train1]\n",
        "tmp = cids_val4.tolist()\n",
        "indexes_val = [tmp.index(i) for i in cids_val1]\n",
        "tmp = cids_test4.tolist()\n",
        "indexes_test = [tmp.index(i) for i in cids_test1]\n",
        "\n",
        "cids_train4 = cids_train4[indexes]\n",
        "cids_val4 = cids_val4[indexes_val]\n",
        "cids_test4 = cids_test4[indexes_test]\n",
        "\n",
        "chem_embeddings_train4 = chem_embeddings_train4[indexes]\n",
        "text_embeddings_train4 = text_embeddings_train4[indexes]\n",
        "chem_embeddings_val4 = chem_embeddings_val4[indexes_val]\n",
        "text_embeddings_val4 = text_embeddings_val4[indexes_val]\n",
        "chem_embeddings_test4 = chem_embeddings_test4[indexes_test]\n",
        "text_embeddings_test4 = text_embeddings_test4[indexes_test]\n",
        "\n",
        "\n",
        "tmp = cids_train5.tolist()\n",
        "indexes = [tmp.index(i) for i in cids_train1]\n",
        "tmp = cids_val5.tolist()\n",
        "indexes_val = [tmp.index(i) for i in cids_val1]\n",
        "tmp = cids_test5.tolist()\n",
        "indexes_test = [tmp.index(i) for i in cids_test1]\n",
        "\n",
        "cids_train5 = cids_train5[indexes]\n",
        "cids_val5 = cids_val5[indexes_val]\n",
        "cids_test5 = cids_test5[indexes_test]\n",
        "\n",
        "chem_embeddings_train5 = chem_embeddings_train5[indexes]\n",
        "text_embeddings_train5 = text_embeddings_train5[indexes]\n",
        "chem_embeddings_val5 = chem_embeddings_val5[indexes_val]\n",
        "text_embeddings_val5 = text_embeddings_val5[indexes_val]\n",
        "chem_embeddings_test5 = chem_embeddings_test5[indexes_test]\n",
        "text_embeddings_test5 = text_embeddings_test5[indexes_test]\n",
        "\n",
        "\n",
        "tmp = cids_train6.tolist()\n",
        "indexes = [tmp.index(i) for i in cids_train1]\n",
        "tmp = cids_val6.tolist()\n",
        "indexes_val = [tmp.index(i) for i in cids_val1]\n",
        "tmp = cids_test6.tolist()\n",
        "indexes_test = [tmp.index(i) for i in cids_test1]\n",
        "\n",
        "cids_train6 = cids_train6[indexes]\n",
        "cids_val6 = cids_val6[indexes_val]\n",
        "cids_test6 = cids_test6[indexes_test]\n",
        "\n",
        "chem_embeddings_train6 = chem_embeddings_train6[indexes]\n",
        "text_embeddings_train6 = text_embeddings_train6[indexes]\n",
        "chem_embeddings_val6 = chem_embeddings_val6[indexes_val]\n",
        "text_embeddings_val6 = text_embeddings_val6[indexes_val]\n",
        "chem_embeddings_test6 = chem_embeddings_test6[indexes_test]\n",
        "text_embeddings_test6 = text_embeddings_test6[indexes_test]\n",
        "\n",
        "\n",
        "all_chem_embbedings1 = np.concatenate((chem_embeddings_train1, chem_embeddings_val1, chem_embeddings_test1), axis = 0)\n",
        "all_chem_embbedings2 = np.concatenate((chem_embeddings_train2, chem_embeddings_val2, chem_embeddings_test2), axis = 0)\n",
        "all_chem_embbedings3 = np.concatenate((chem_embeddings_train3, chem_embeddings_val3, chem_embeddings_test3), axis = 0)\n",
        "all_chem_embbedings4 = np.concatenate((chem_embeddings_train4, chem_embeddings_val4, chem_embeddings_test4), axis = 0)\n",
        "all_chem_embbedings5 = np.concatenate((chem_embeddings_train5, chem_embeddings_val5, chem_embeddings_test5), axis = 0)\n",
        "all_chem_embbedings6 = np.concatenate((chem_embeddings_train6, chem_embeddings_val6, chem_embeddings_test6), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "v1c3q5tMX8S5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def memory_efficient_similarity_matrix_custom(func, embedding1, embedding2, chunk_size = 1000):\n",
        "    rows = embedding1.shape[0]\n",
        "\n",
        "    num_chunks = int(np.ceil(rows / chunk_size))\n",
        "\n",
        "    for i in range(num_chunks):\n",
        "        end_chunk = (i+1)*(chunk_size) if (i+1)*(chunk_size) < rows else rows #account for smaller chunk at end...\n",
        "        yield func(embedding1[i*chunk_size:end_chunk,:], embedding2)\n",
        "\n",
        "\n",
        "text_chem_cos1 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_train1, all_chem_embbedings1)\n",
        "text_chem_cos_val1 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_val1, all_chem_embbedings1)\n",
        "text_chem_cos_test1 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_test1, all_chem_embbedings1)\n",
        "\n",
        "text_chem_cos2 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_train2, all_chem_embbedings2)\n",
        "text_chem_cos_val2 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_val2, all_chem_embbedings2)\n",
        "text_chem_cos_test2 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_test2, all_chem_embbedings2)\n",
        "\n",
        "text_chem_cos3 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_train3, all_chem_embbedings3)\n",
        "text_chem_cos_val3 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_val3, all_chem_embbedings3)\n",
        "text_chem_cos_test3 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_test3, all_chem_embbedings3)\n",
        "\n",
        "text_chem_cos4 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_train4, all_chem_embbedings4)\n",
        "text_chem_cos_val4 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_val4, all_chem_embbedings4)\n",
        "text_chem_cos_test4 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_test4, all_chem_embbedings4)\n",
        "\n",
        "text_chem_cos5 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_train5, all_chem_embbedings5)\n",
        "text_chem_cos_val5 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_val5, all_chem_embbedings5)\n",
        "text_chem_cos_test5 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_test5, all_chem_embbedings5)\n",
        "\n",
        "text_chem_cos6 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_train6, all_chem_embbedings6)\n",
        "text_chem_cos_val6 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_val6, all_chem_embbedings6)\n",
        "text_chem_cos_test6 = memory_efficient_similarity_matrix_custom(cosine_similarity, text_embeddings_test6, all_chem_embbedings6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XHaXqxabUMIM"
      },
      "outputs": [],
      "source": [
        "n_train = len(cids_train1)\n",
        "n_val = len(cids_val2)\n",
        "n_test = len(cids_test1)\n",
        "n = n_train + n_val + n_test\n",
        "\n",
        "offset_val = n_train\n",
        "offset_test = n_train + n_val\n",
        "\n",
        "cids_all = np.concatenate((cids_train1, cids_val1, cids_test1), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IeiE_f5sfXi_"
      },
      "outputs": [],
      "source": [
        "tr_ranks_avg = np.zeros((n_train, n))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8YLeGjn3lw0U"
      },
      "outputs": [],
      "source": [
        "val_avg_ranks = np.zeros((n_val, n))\n",
        "test_avg_ranks = np.zeros((n_test, n))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KSJO3N3rX-RO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd48fbbf-57c6-4842-b428-1e51bf086da4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 train processed.\n",
            "2000 train processed.\n",
            "3000 train processed.\n",
            "4000 train processed.\n",
            "5000 train processed.\n",
            "6000 train processed.\n",
            "7000 train processed.\n",
            "8000 train processed.\n",
            "9000 train processed.\n",
            "10000 train processed.\n",
            "11000 train processed.\n",
            "12000 train processed.\n",
            "13000 train processed.\n",
            "14000 train processed.\n",
            "15000 train processed.\n",
            "16000 train processed.\n",
            "17000 train processed.\n",
            "18000 train processed.\n",
            "19000 train processed.\n",
            "20000 train processed.\n",
            "21000 train processed.\n",
            "22000 train processed.\n",
            "23000 train processed.\n",
            "24000 train processed.\n",
            "25000 train processed.\n",
            "26000 train processed.\n",
            "\n",
            "Training Mean rank: 3.773401999394123\n",
            "Hits at 1: 0.43077855195395337\n",
            "Hits at 10: 0.9351711602544683\n",
            "Hits at 100: 0.9992047864283551\n",
            "Hits at 500: 1.0\n",
            "Hits at 1000: 1.0\n",
            "Trainng MRR: 0.6027827503823702\n"
          ]
        }
      ],
      "source": [
        "#For space 1:\n",
        "\n",
        "\n",
        "tr_correct1 = np.zeros(len(cids_train1))\n",
        "\n",
        "hits_at_one = 0\n",
        "hits_at_ten = 0\n",
        "hits_at_100 = 0\n",
        "hits_at_500 = 0\n",
        "hits_at_1000 = 0\n",
        "ranks1 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos1):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs) #rank is actually double argsort.\n",
        "\n",
        "        tr_ranks_avg[j,:] = tr_ranks_avg[j,:] + ranks\n",
        "\n",
        "\n",
        "        tr_correct1[j] = ranks[j] + 1\n",
        "        rank = ranks[j] + 1\n",
        "        ranks1.append(rank)\n",
        "\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"train processed.\")\n",
        "\n",
        "ranks1 = np.array(ranks1)\n",
        "\n",
        "print()\n",
        "print(\"Training Mean rank:\", np.mean(ranks1))\n",
        "print(\"Hits at 1:\", np.mean(ranks1 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks1 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks1 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks1 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks1 <= 1000))\n",
        "\n",
        "print(\"Trainng MRR:\", np.mean(1/np.array(ranks1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WHCE8t4xkEEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b10b74d6-44f1-4c61-ef6f-262fe8af3e07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 val processed.\n",
            "2000 val processed.\n",
            "3000 val processed.\n",
            "\n",
            "Val Mean rank: 25.33292941532869\n",
            "Hits at 1: 0.33262647682520446\n",
            "Hits at 10: 0.8270221145107544\n",
            "Hits at 100: 0.966373826113299\n",
            "Hits at 500: 0.9927294759163889\n",
            "Hits at 1000: 0.9954559224477431\n",
            "Validation MRR: 0.49462557204654617\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ranks_val1 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_val1):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs)\n",
        "\n",
        "        val_avg_ranks[j,:] = val_avg_ranks[j,:] + ranks\n",
        "\n",
        "        rank = ranks[j+offset_val] + 1\n",
        "        ranks_val1.append(rank)\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"val processed.\")\n",
        "\n",
        "\n",
        "ranks_val1 = np.array(ranks_val1)\n",
        "\n",
        "print()\n",
        "print(\"Val Mean rank:\", np.mean(ranks_val1))\n",
        "print(\"Hits at 1:\", np.mean(ranks_val1 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_val1 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_val1 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_val1 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_val1 <= 1000))\n",
        "\n",
        "print(\"Validation MRR:\", np.mean(1/ranks_val1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BHtt2av9sTSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8f68b26-f77c-47d1-dd61-dd1045a2a7f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 test processed.\n",
            "2000 test processed.\n",
            "3000 test processed.\n",
            "\n",
            "Test Mean rank: 26.569221448046047\n",
            "Hits at 1: 0.32838533777643136\n",
            "Hits at 10: 0.8273250530142381\n",
            "Hits at 100: 0.9712208421690397\n",
            "Hits at 500: 0.9921235989094214\n",
            "Hits at 1000: 0.9966676764616783\n",
            "Test MRR: 0.4929061871869085\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "ranks_test1 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_test1):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs)\n",
        "\n",
        "        test_avg_ranks[j,:] = test_avg_ranks[j,:] + ranks\n",
        "\n",
        "        rank = ranks[j+offset_test] + 1\n",
        "        ranks_test1.append(rank)\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"test processed.\")\n",
        "\n",
        "ranks_test1 = np.array(ranks_test1)\n",
        "\n",
        "print()\n",
        "print(\"Test Mean rank:\", np.mean(ranks_test1))\n",
        "print(\"Hits at 1:\", np.mean(ranks_test1 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_test1 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_test1 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_test1 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_test1 <= 1000))\n",
        "\n",
        "print(\"Test MRR:\", np.mean(1/ranks_test1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FTGLQhjCcNcQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12469565-db81-49b8-8627-2d97f7503049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 train processed.\n",
            "2000 train processed.\n",
            "3000 train processed.\n",
            "4000 train processed.\n",
            "5000 train processed.\n",
            "6000 train processed.\n",
            "7000 train processed.\n",
            "8000 train processed.\n",
            "9000 train processed.\n",
            "10000 train processed.\n",
            "11000 train processed.\n",
            "12000 train processed.\n",
            "13000 train processed.\n",
            "14000 train processed.\n",
            "15000 train processed.\n",
            "16000 train processed.\n",
            "17000 train processed.\n",
            "18000 train processed.\n",
            "19000 train processed.\n",
            "20000 train processed.\n",
            "21000 train processed.\n",
            "22000 train processed.\n",
            "23000 train processed.\n",
            "24000 train processed.\n",
            "25000 train processed.\n",
            "26000 train processed.\n",
            "\n",
            "Training Mean rank: 3.777794607694638\n",
            "Hits at 1: 0.4286579824295668\n",
            "Hits at 10: 0.9322932444713723\n",
            "Hits at 100: 0.9995834595577098\n",
            "Hits at 500: 1.0\n",
            "Hits at 1000: 1.0\n",
            "Training MRR: 0.5998095560970966\n"
          ]
        }
      ],
      "source": [
        "#For space 2:\n",
        "\n",
        "ranks2 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos2):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs)\n",
        "\n",
        "        tr_ranks_avg[j,:] = tr_ranks_avg[j,:] + ranks\n",
        "\n",
        "        rank = ranks[j] + 1\n",
        "        ranks2.append(rank)\n",
        "\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"train processed.\")\n",
        "\n",
        "ranks2 = np.array(ranks2)\n",
        "\n",
        "print()\n",
        "print(\"Training Mean rank:\", np.mean(ranks2))\n",
        "print(\"Hits at 1:\", np.mean(ranks2 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks2 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks2 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks2 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks2 <= 1000))\n",
        "\n",
        "print(\"Training MRR:\", np.mean(1/ranks2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BJVdQ3gnkF6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c99fcde3-c38a-4311-fb54-486564c5662e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 val processed.\n",
            "2000 val processed.\n",
            "3000 val processed.\n",
            "\n",
            "Val Mean rank: 27.55528627688579\n",
            "Hits at 1: 0.3238412602241745\n",
            "Hits at 10: 0.8124810663435322\n",
            "Hits at 100: 0.9706149651620721\n",
            "Hits at 500: 0.9921235989094214\n",
            "Hits at 1000: 0.9972735534686459\n",
            "Validation MRR: 0.48576901772929704\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ranks_val2 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_val2):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs)\n",
        "\n",
        "        val_avg_ranks[j,:] = val_avg_ranks[j,:] + ranks\n",
        "\n",
        "        rank = ranks[j+offset_val] + 1\n",
        "        ranks_val2.append(rank)\n",
        "\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"val processed.\")\n",
        "\n",
        "\n",
        "ranks_val2 = np.array(ranks_val2)\n",
        "\n",
        "print()\n",
        "print(\"Val Mean rank:\", np.mean(ranks_val2))\n",
        "print(\"Hits at 1:\", np.mean(ranks_val2 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_val2 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_val2 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_val2 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_val2 <= 1000))\n",
        "\n",
        "print(\"Validation MRR:\", np.mean(1/ranks_val2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b--eYvc1tmdB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1bb27a0-c9a8-47e5-825c-11a2ab31305e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 test processed.\n",
            "2000 test processed.\n",
            "3000 test processed.\n",
            "\n",
            "Test Mean rank: 30.252953650408966\n",
            "Hits at 1: 0.33292941532868825\n",
            "Hits at 10: 0.8276279915177219\n",
            "Hits at 100: 0.97364435019691\n",
            "Hits at 500: 0.9945471069372918\n",
            "Hits at 1000: 0.9966676764616783\n",
            "Test MRR: 0.49152052959419673\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ranks_test2 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_test2):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs)\n",
        "\n",
        "        test_avg_ranks[j,:] = test_avg_ranks[j,:] + ranks\n",
        "\n",
        "        rank = ranks[j+offset_test] + 1\n",
        "        ranks_test2.append(rank)\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"test processed.\")\n",
        "\n",
        "ranks_test2 = np.array(ranks_test2)\n",
        "\n",
        "print()\n",
        "print(\"Test Mean rank:\", np.mean(ranks_test2))\n",
        "print(\"Hits at 1:\", np.mean(ranks_test2 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_test2 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_test2 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_test2 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_test2 <= 1000))\n",
        "\n",
        "print(\"Test MRR:\", np.mean(1/ranks_test2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "F-O544rBjuPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d33ab0e-0796-4c2d-eb0d-d0e87114c391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 train processed.\n",
            "2000 train processed.\n",
            "3000 train processed.\n",
            "4000 train processed.\n",
            "5000 train processed.\n",
            "6000 train processed.\n",
            "7000 train processed.\n",
            "8000 train processed.\n",
            "9000 train processed.\n",
            "10000 train processed.\n",
            "11000 train processed.\n",
            "12000 train processed.\n",
            "13000 train processed.\n",
            "14000 train processed.\n",
            "15000 train processed.\n",
            "16000 train processed.\n",
            "17000 train processed.\n",
            "18000 train processed.\n",
            "19000 train processed.\n",
            "20000 train processed.\n",
            "21000 train processed.\n",
            "22000 train processed.\n",
            "23000 train processed.\n",
            "24000 train processed.\n",
            "25000 train processed.\n",
            "26000 train processed.\n",
            "\n",
            "Training Mean rank: 3.7033096031505606\n",
            "Hits at 1: 0.4342244774310815\n",
            "Hits at 10: 0.9346410178733717\n",
            "Hits at 100: 0.9996213268706453\n",
            "Hits at 500: 1.0\n",
            "Hits at 1000: 1.0\n",
            "Training MRR: 0.6054544374568394\n"
          ]
        }
      ],
      "source": [
        "#For space 3:\n",
        "\n",
        "ranks3 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos3):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs)\n",
        "\n",
        "        tr_ranks_avg[j,:] = tr_ranks_avg[j,:] + ranks\n",
        "\n",
        "        rank = ranks[j] + 1\n",
        "        ranks3.append(rank)\n",
        "\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"train processed.\")\n",
        "\n",
        "ranks3 = np.array(ranks3)\n",
        "\n",
        "print()\n",
        "print(\"Training Mean rank:\", np.mean(ranks3))\n",
        "print(\"Hits at 1:\", np.mean(ranks3 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks3 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks3 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks3 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks3 <= 1000))\n",
        "\n",
        "print(\"Training MRR:\", np.mean(1/ranks3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XUHkwFDij3Wo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9bd77db-e16d-4c12-9c57-390732aa2d17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 val processed.\n",
            "2000 val processed.\n",
            "3000 val processed.\n",
            "\n",
            "Val Mean rank: 24.92275068161163\n",
            "Hits at 1: 0.33020296879733413\n",
            "Hits at 10: 0.8242956679794002\n",
            "Hits at 100: 0.9700090881551046\n",
            "Hits at 500: 0.9918206604059376\n",
            "Hits at 1000: 0.9957588609512269\n",
            "Validation MRR: 0.4926737813962398\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ranks_val3 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_val3):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs)\n",
        "\n",
        "        val_avg_ranks[j,:] = val_avg_ranks[j,:] + ranks\n",
        "\n",
        "        rank = ranks[j+offset_val] + 1\n",
        "        ranks_val3.append(rank)\n",
        "\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"val processed.\")\n",
        "\n",
        "\n",
        "ranks_val3 = np.array(ranks_val3)\n",
        "\n",
        "print()\n",
        "print(\"Val Mean rank:\", np.mean(ranks_val3))\n",
        "print(\"Hits at 1:\", np.mean(ranks_val3 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_val3 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_val3 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_val3 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_val3 <= 1000))\n",
        "\n",
        "print(\"Validation MRR:\", np.mean(1/ranks_val3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8ejG82D7aG9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae34db51-4946-46f5-ec08-987da2534214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['6106' '439524' '857' ... '134160309' '134160310' '134160311']\n",
            "28483\n"
          ]
        }
      ],
      "source": [
        "tmp = cids_all[np.argsort(val_avg_ranks[1396,:])]\n",
        "print(tmp)\n",
        "print(np.where(tmp == '45359507')[0][0] + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lBQAScCBj9_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd22793e-757d-4782-deff-0dcf9a89f74b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 test processed.\n",
            "2000 test processed.\n",
            "3000 test processed.\n",
            "\n",
            "Test Mean rank: 29.471978188427748\n",
            "Hits at 1: 0.34262344744016965\n",
            "Hits at 10: 0.8297485610421085\n",
            "Hits at 100: 0.9742502272038777\n",
            "Hits at 500: 0.9933353529233565\n",
            "Hits at 1000: 0.9963647379581945\n",
            "Test MRR: 0.5037819885980604\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ranks_test3 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_test3):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs)\n",
        "\n",
        "        test_avg_ranks[j,:] = test_avg_ranks[j,:] + ranks\n",
        "\n",
        "        rank = ranks[j+offset_test] + 1\n",
        "        ranks_test3.append(rank)\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"test processed.\")\n",
        "\n",
        "ranks_test3 = np.array(ranks_test3)\n",
        "\n",
        "print()\n",
        "print(\"Test Mean rank:\", np.mean(ranks_test3))\n",
        "print(\"Hits at 1:\", np.mean(ranks_test3 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_test3 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_test3 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_test3 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_test3 <= 1000))\n",
        "\n",
        "print(\"Test MRR:\", np.mean(1/ranks_test3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6fVP9qVuZJSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a4e1004-5463-4d34-d7a9-88efa7db7683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 train processed.\n",
            "2000 train processed.\n",
            "3000 train processed.\n",
            "4000 train processed.\n",
            "5000 train processed.\n",
            "6000 train processed.\n",
            "7000 train processed.\n",
            "8000 train processed.\n",
            "9000 train processed.\n",
            "10000 train processed.\n",
            "11000 train processed.\n",
            "12000 train processed.\n",
            "13000 train processed.\n",
            "14000 train processed.\n",
            "15000 train processed.\n",
            "16000 train processed.\n",
            "17000 train processed.\n",
            "18000 train processed.\n",
            "19000 train processed.\n",
            "20000 train processed.\n",
            "21000 train processed.\n",
            "22000 train processed.\n",
            "23000 train processed.\n",
            "24000 train processed.\n",
            "25000 train processed.\n",
            "26000 train processed.\n",
            "\n",
            "Training Mean rank: 3.6195092396243562\n",
            "Hits at 1: 0.4310436231445017\n",
            "Hits at 10: 0.9364586488942744\n",
            "Hits at 100: 0.9999621326870646\n",
            "Hits at 500: 1.0\n",
            "Hits at 1000: 1.0\n",
            "Training MRR: 0.6040432238560232\n"
          ]
        }
      ],
      "source": [
        "#For space 4:\n",
        "\n",
        "ranks4 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos4):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs)\n",
        "\n",
        "        tr_ranks_avg[j,:] = tr_ranks_avg[j,:] + ranks\n",
        "\n",
        "        rank = ranks[j] + 1\n",
        "        ranks4.append(rank)\n",
        "\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"train processed.\")\n",
        "\n",
        "ranks4 = np.array(ranks4)\n",
        "\n",
        "print()\n",
        "print(\"Training Mean rank:\", np.mean(ranks4))\n",
        "print(\"Hits at 1:\", np.mean(ranks4 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks4 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks4 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks4 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks4 <= 1000))\n",
        "\n",
        "print(\"Training MRR:\", np.mean(1/ranks4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bdtt4pqoZSG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f0d060-37b3-4da5-c320-69f8e92729a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 val processed.\n",
            "2000 val processed.\n",
            "3000 val processed.\n",
            "\n",
            "Val Mean rank: 32.12450772493184\n",
            "Hits at 1: 0.33959406240533174\n",
            "Hits at 10: 0.8309603150560436\n",
            "Hits at 100: 0.9669797031202666\n",
            "Hits at 500: 0.9909118448954862\n",
            "Hits at 1000: 0.9930324144198728\n",
            "Validation MRR: 0.5030397550109146\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ranks_val4 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_val4):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs)\n",
        "\n",
        "        val_avg_ranks[j,:] = val_avg_ranks[j,:] + ranks\n",
        "\n",
        "\n",
        "        rank = ranks[j+offset_val] + 1\n",
        "        ranks_val4.append(rank)\n",
        "\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"val processed.\")\n",
        "\n",
        "\n",
        "ranks_val4 = np.array(ranks_val4)\n",
        "\n",
        "print()\n",
        "print(\"Val Mean rank:\", np.mean(ranks_val4))\n",
        "print(\"Hits at 1:\", np.mean(ranks_val4 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_val4 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_val4 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_val4 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_val4 <= 1000))\n",
        "\n",
        "print(\"Validation MRR:\", np.mean(1/ranks_val4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mgb8DZyGZaeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dce25ca-b478-4498-bd2f-6e016980d512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 test processed.\n",
            "2000 test processed.\n",
            "3000 test processed.\n",
            "\n",
            "Test Mean rank: 24.218418661011814\n",
            "Hits at 1: 0.34989397152378066\n",
            "Hits at 10: 0.8367161466222357\n",
            "Hits at 100: 0.9760678582247804\n",
            "Hits at 500: 0.9933353529233565\n",
            "Hits at 1000: 0.9966676764616783\n",
            "Test MRR: 0.5110214842104321\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ranks_test4 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_test4):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs)\n",
        "\n",
        "        test_avg_ranks[j,:] = test_avg_ranks[j,:] + ranks\n",
        "\n",
        "        rank = ranks[j+offset_test] + 1\n",
        "        ranks_test4.append(rank)\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"test processed.\")\n",
        "\n",
        "ranks_test4 = np.array(ranks_test4)\n",
        "\n",
        "print()\n",
        "print(\"Test Mean rank:\", np.mean(ranks_test4))\n",
        "print(\"Hits at 1:\", np.mean(ranks_test4 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_test4 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_test4 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_test4 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_test4 <= 1000))\n",
        "\n",
        "print(\"Test MRR:\", np.mean(1/ranks_test4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "UYBg8DgLLF77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04dbaf7d-b912-46e2-a957-b00d42aaf486"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 train processed.\n",
            "2000 train processed.\n",
            "3000 train processed.\n",
            "4000 train processed.\n",
            "5000 train processed.\n",
            "6000 train processed.\n",
            "7000 train processed.\n",
            "8000 train processed.\n",
            "9000 train processed.\n",
            "10000 train processed.\n",
            "11000 train processed.\n",
            "12000 train processed.\n",
            "13000 train processed.\n",
            "14000 train processed.\n",
            "15000 train processed.\n",
            "16000 train processed.\n",
            "17000 train processed.\n",
            "18000 train processed.\n",
            "19000 train processed.\n",
            "20000 train processed.\n",
            "21000 train processed.\n",
            "22000 train processed.\n",
            "23000 train processed.\n",
            "24000 train processed.\n",
            "25000 train processed.\n",
            "26000 train processed.\n",
            "\n",
            "Training Mean rank: 3.6427597697667373\n",
            "Hits at 1: 0.43661011814601636\n",
            "Hits at 10: 0.9365722508330809\n",
            "Hits at 100: 1.0\n",
            "Hits at 500: 1.0\n",
            "Hits at 1000: 1.0\n",
            "Training MRR: 0.6067333791962036\n"
          ]
        }
      ],
      "source": [
        "#For space 5:\n",
        "\n",
        "ranks5 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos5):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs)\n",
        "\n",
        "        tr_ranks_avg[j,:] = tr_ranks_avg[j,:] + ranks\n",
        "\n",
        "        rank = ranks[j] + 1\n",
        "        ranks5.append(rank)\n",
        "\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"train processed.\")\n",
        "\n",
        "ranks5 = np.array(ranks5)\n",
        "\n",
        "print()\n",
        "print(\"Training Mean rank:\", np.mean(ranks5))\n",
        "print(\"Hits at 1:\", np.mean(ranks5 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks5 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks5 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks5 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks5 <= 1000))\n",
        "\n",
        "print(\"Training MRR:\", np.mean(1/ranks5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ciC1UHCULOHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f40a607c-2927-44ca-f6b7-d916c83fc16d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 val processed.\n",
            "2000 val processed.\n",
            "3000 val processed.\n",
            "\n",
            "Val Mean rank: 28.23962435625568\n",
            "Hits at 1: 0.3286882762799152\n",
            "Hits at 10: 0.8358073311117843\n",
            "Hits at 100: 0.9697061496516207\n",
            "Hits at 500: 0.9924265374129052\n",
            "Hits at 1000: 0.9954559224477431\n",
            "Validation MRR: 0.49285549439178195\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ranks_val5 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_val5):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs)\n",
        "\n",
        "        val_avg_ranks[j,:] = val_avg_ranks[j,:] + ranks\n",
        "\n",
        "        rank = ranks[j+offset_val] + 1\n",
        "        ranks_val5.append(rank)\n",
        "\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"val processed.\")\n",
        "\n",
        "\n",
        "ranks_val5 = np.array(ranks_val5)\n",
        "\n",
        "print()\n",
        "print(\"Val Mean rank:\", np.mean(ranks_val5))\n",
        "print(\"Hits at 1:\", np.mean(ranks_val5 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_val5 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_val5 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_val5 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_val5 <= 1000))\n",
        "\n",
        "print(\"Validation MRR:\", np.mean(1/ranks_val5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "cnNAtefpLUIo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be6fb4fe-5e66-446a-ad67-889db5981cd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 test processed.\n",
            "2000 test processed.\n",
            "3000 test processed.\n",
            "\n",
            "Test Mean rank: 27.697061496516206\n",
            "Hits at 1: 0.34656164798545896\n",
            "Hits at 10: 0.8339897000908816\n",
            "Hits at 100: 0.9745531657073614\n",
            "Hits at 500: 0.9930324144198728\n",
            "Hits at 1000: 0.9960617994547107\n",
            "Test MRR: 0.5066356706883463\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ranks_test5 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_test5):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs)\n",
        "\n",
        "        test_avg_ranks[j,:] = test_avg_ranks[j,:] + ranks\n",
        "\n",
        "        rank = ranks[j+offset_test] + 1\n",
        "        ranks_test5.append(rank)\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"test processed.\")\n",
        "\n",
        "ranks_test5 = np.array(ranks_test5)\n",
        "\n",
        "print()\n",
        "print(\"Test Mean rank:\", np.mean(ranks_test5))\n",
        "print(\"Hits at 1:\", np.mean(ranks_test5 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_test5 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_test5 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_test5 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_test5 <= 1000))\n",
        "\n",
        "print(\"Test MRR:\", np.mean(1/ranks_test5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "THVsmON8LZhD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f777ae8a-7917-40ff-909f-2de2853edb62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 train processed.\n",
            "2000 train processed.\n",
            "3000 train processed.\n",
            "4000 train processed.\n",
            "5000 train processed.\n",
            "6000 train processed.\n",
            "7000 train processed.\n",
            "8000 train processed.\n",
            "9000 train processed.\n",
            "10000 train processed.\n",
            "11000 train processed.\n",
            "12000 train processed.\n",
            "13000 train processed.\n",
            "14000 train processed.\n",
            "15000 train processed.\n",
            "16000 train processed.\n",
            "17000 train processed.\n",
            "18000 train processed.\n",
            "19000 train processed.\n",
            "20000 train processed.\n",
            "21000 train processed.\n",
            "22000 train processed.\n",
            "23000 train processed.\n",
            "24000 train processed.\n",
            "25000 train processed.\n",
            "26000 train processed.\n",
            "\n",
            "Training Mean rank: 3.569183580733111\n",
            "Hits at 1: 0.4374810663435323\n",
            "Hits at 10: 0.939374431990306\n",
            "Hits at 100: 0.999924265374129\n",
            "Hits at 500: 1.0\n",
            "Hits at 1000: 1.0\n",
            "Training MRR: 0.6093118704602868\n"
          ]
        }
      ],
      "source": [
        "#For space 6:\n",
        "\n",
        "ranks6 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos6):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs)\n",
        "\n",
        "        tr_ranks_avg[j,:] = tr_ranks_avg[j,:] + ranks\n",
        "\n",
        "        rank = ranks[j] + 1\n",
        "        ranks6.append(rank)\n",
        "\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"train processed.\")\n",
        "\n",
        "ranks6 = np.array(ranks6)\n",
        "\n",
        "print()\n",
        "print(\"Training Mean rank:\", np.mean(ranks6))\n",
        "print(\"Hits at 1:\", np.mean(ranks6 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks6 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks6 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks6 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks6 <= 1000))\n",
        "\n",
        "print(\"Training MRR:\", np.mean(1/ranks6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EMx_msazLf0M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9018ac5-341d-4bc2-a6fa-d05336dd9422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 val processed.\n",
            "2000 val processed.\n",
            "3000 val processed.\n",
            "\n",
            "Val Mean rank: 31.196304150257497\n",
            "Hits at 1: 0.35019691002726444\n",
            "Hits at 10: 0.8309603150560436\n",
            "Hits at 100: 0.9697061496516207\n",
            "Hits at 500: 0.9906089063920024\n",
            "Hits at 1000: 0.9942441684338079\n",
            "Validation MRR: 0.5077238195493112\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ranks_val6 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_val6):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs)\n",
        "\n",
        "        val_avg_ranks[j,:] = val_avg_ranks[j,:] + ranks\n",
        "\n",
        "        rank = ranks[j+offset_val] + 1\n",
        "        ranks_val6.append(rank)\n",
        "\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"val processed.\")\n",
        "\n",
        "\n",
        "ranks_val6 = np.array(ranks_val6)\n",
        "\n",
        "print()\n",
        "print(\"Val Mean rank:\", np.mean(ranks_val6))\n",
        "print(\"Hits at 1:\", np.mean(ranks_val6 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_val6 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_val6 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_val6 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_val6 <= 1000))\n",
        "\n",
        "print(\"Validation MRR:\", np.mean(1/ranks_val6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-h5XSGf3LmHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c22fa8f6-0115-408b-f1bc-07096c7c41c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 test processed.\n",
            "2000 test processed.\n",
            "3000 test processed.\n",
            "\n",
            "Test Mean rank: 22.836413208118753\n",
            "Hits at 1: 0.3392911239018479\n",
            "Hits at 10: 0.833383823083914\n",
            "Hits at 100: 0.9763707967282642\n",
            "Hits at 500: 0.9936382914268403\n",
            "Hits at 1000: 0.9960617994547107\n",
            "Test MRR: 0.5037537684179033\n"
          ]
        }
      ],
      "source": [
        "\n",
        "ranks_test6 = []\n",
        "j = 0 #keep track of all loops\n",
        "for i, emb in enumerate(text_chem_cos_test6):\n",
        "    for k in range(emb.shape[0]):\n",
        "        cid_locs = np.argsort(emb[k,:])[::-1]\n",
        "        ranks = np.argsort(cid_locs)\n",
        "\n",
        "        test_avg_ranks[j,:] = test_avg_ranks[j,:] + ranks\n",
        "\n",
        "        rank = ranks[j+offset_test] + 1\n",
        "        ranks_test6.append(rank)\n",
        "\n",
        "        j += 1\n",
        "        if (j) % 1000 == 0: print((j), \"test processed.\")\n",
        "\n",
        "ranks_test6 = np.array(ranks_test6)\n",
        "\n",
        "print()\n",
        "print(\"Test Mean rank:\", np.mean(ranks_test6))\n",
        "print(\"Hits at 1:\", np.mean(ranks_test6 <= 1))\n",
        "print(\"Hits at 10:\", np.mean(ranks_test6 <= 10))\n",
        "print(\"Hits at 100:\", np.mean(ranks_test6 <= 100))\n",
        "print(\"Hits at 500:\", np.mean(ranks_test6 <= 500))\n",
        "print(\"Hits at 1000:\", np.mean(ranks_test6 <= 1000))\n",
        "\n",
        "print(\"Test MRR:\", np.mean(1/ranks_test6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P3nT85ythbh"
      },
      "source": [
        "#Rerank from sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "b4tFZs1B1afY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11d79c2d-e28e-40d6-c3b0-fafe6c386048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.582777946076946\n",
            "%1: 0.5575583156619206\n",
            "%10: 0.9703120266585883\n",
            "%100: 1.0\n",
            "Trainng MRR: 0.708569958676293\n"
          ]
        }
      ],
      "source": [
        "\n",
        "sorted = np.argsort(tr_ranks_avg)\n",
        "new_tr_ranks = np.diag(np.argsort(sorted)) + 1\n",
        "\n",
        "print(np.mean(new_tr_ranks))\n",
        "print(\"%1:\", np.mean(new_tr_ranks <= 1))\n",
        "print(\"%10:\", np.mean(new_tr_ranks <= 10))\n",
        "print(\"%100:\", np.mean(new_tr_ranks <= 100))\n",
        "\n",
        "print(\"Trainng MRR:\", np.mean(1/np.array(new_tr_ranks)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "EysOkgIrz2pf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1538d884-3464-48a1-cc03-1f580a793743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17.837624962132686\n",
            "%1: 0.41805513480763407\n",
            "%10: 0.884580430172675\n",
            "%100: 0.9781884277491669\n",
            "Validation MRR: 0.5797269257879241\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "sorted = np.argsort(val_avg_ranks)\n",
        "val_final_ranks = np.argsort(sorted) + 1\n",
        "new_val_ranks = np.diag(val_final_ranks[:,offset_val:offset_test])\n",
        "\n",
        "print(np.mean(new_val_ranks))\n",
        "print(\"%1:\", np.mean(new_val_ranks <= 1))\n",
        "print(\"%10:\", np.mean(new_val_ranks <= 10))\n",
        "print(\"%100:\", np.mean(new_val_ranks <= 100))\n",
        "\n",
        "print(\"Validation MRR:\", np.mean(1/np.array(new_val_ranks)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "LKwl8NzwuUF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7550ca7d-d1cb-4269-f386-96e41416b417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17.77158436837322\n",
            "%1: 0.4359285065131778\n",
            "%10: 0.8900333232353832\n",
            "%100: 0.9851560133292941\n",
            "Test MRR: 0.5917850369537417\n"
          ]
        }
      ],
      "source": [
        "\n",
        "sorted = np.argsort(test_avg_ranks)\n",
        "test_final_ranks = np.argsort(sorted) + 1\n",
        "new_test_ranks = np.diag(test_final_ranks[:,offset_test:])\n",
        "\n",
        "print(np.mean(new_test_ranks))\n",
        "print(\"%1:\", np.mean(new_test_ranks <= 1))\n",
        "print(\"%10:\", np.mean(new_test_ranks <= 10))\n",
        "print(\"%100:\", np.mean(new_test_ranks <= 100))\n",
        "\n",
        "print(\"Test MRR:\", np.mean(1/new_test_ranks))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}